# DINO: Emerging Properties in Self-Supervised Vision Transformer(2021)

> - Authors: Mathilde Caron, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal, Piotr Bojanowski, Armand Joulin
> - Published: ICCV 2021
> - Created: 2022년 08월 18일 오후 8:47
> - Tags: Transformer

## Summary
- ViT는 CNN을 대체하는 모델로 사용되고 있음. 그러나 CNN과 비교했을 때, 명확한 이점을 찾기 어려움
- NLP의 Transformers로부터 영감받아, ViT에 self-supervised learning을 적용함 → **DINO**
- DINO의 방법론은 **Codistillation**을 사용함.
  <details>
  <summary> Knowledge Distillation과 Codistillation</summary>
    
    - Knowledge Distillation은 경량화 기법으로, 큰 모델(Teacher Network)로부터 증류한 지식을 작은 모델(Student Network)로 transfer하는 일련의 과정을 의미함
        
      → 이때, 지식 전달 과정에서 Teacher Network의 Weight는 고정됨
  
    - Codistillation은 Student Network와 Teacher Network가 서로 동일한 아키텍처 사용함으로써, Teacher/Student Network가 각 모델에게 지식을 전달함
  </details>

- self-supervised learning을 ViT에 적용함으로써, 다음과 같은 발견을 함
    1. self-supervised ViT의 features에는 이미지의 semantic segmentation에 대한 명확한 정보가 담겨져 있음
        
        → supervised ViT나 CNN에서는 잘 드러나지 않았음
        
    2. self-supervised ViT의 features는 훌륭한 k-NN 분류기가 될 수 있음
        
        → ImageNet에서 78.3%의 top-1 accuracy를 보임
        
    3. momentum encoder, multi-crop training, 작은 patch 크기의 중요성에 대해 다시 한 번 확인함
