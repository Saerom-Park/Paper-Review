# IFSeg: Image-Free Semantic Segmentation via Vision-Language Model(2023)

> - Authors: Sukmin Yun, SeongHyeon Park, Paul Hongsuck Seo, Jinwoo Shin
> - Published: CVPR 2023
> - Created: 2023년 7월 28일 오후 17:21
> - Tags: VL, Segmentation
*** 

## Summary
- 본 논문은 task-specific image나 annotation 없이 target semantic categories 만으로 semantic segmentation을 수행하는 것을 목표로 한 새로운 image-free segmentation 방법을 소개
- word token을 사용해 artificial image segmentation pair를 생성하고, VL 모델을 업데이트 하여 segmentation을 수행하는 간단하면서도 효과적인 VL 기반 self-supervised task인 `IFSeg`를 제안
- random semantic 카테고리(ex. artificial image tokens)의 2D map과 그것에 일치하는 word token map을 생성함으로써 artificial training data를 구축
- Encoder-Decoder 구조의 VL 모델과 VQA(Visual Question Answering) task의 'description + category enumeration' 프로토콜을 사용해, VL 모델이 image token과 semantic category 사이의 cross-modal relationship을 발견하도록 함
- 또한, shape regularization effect와 post processing을 적용함으로써, segmentation quality를 향상시킴
***

## Method
### VL Encoder-Decoder Architecture
- image backbone을 통과하여 얻은 이미지 토큰 $x_I$와 이미지 임베딩 $e_I$와 텍스트 토큰 $x_T$와 임베딩 $e_T$로 VL 모델 학습 
- encoder $f_{enc}$에서는 self-attention 메커니즘으로 transform함으로써 x에 대한 contextualized 임베딩을 생성
- decoder $f_{dec}$에서는 각각의 $f_{enc}(e_x)$에 대해 self-attention과 cross attention 메커니즘으로 transform함으로써 target distribution 예측
- linear transform을 적용하여 logit 생성

### Semantic Segmentation via Encoder-Decoder
#### Task Formulation
- 특정 semantic category word가 여려 개의 sub-word의 dictionary로 토큰화되는 문제를 해결하기 위해, 해당 카테고리를 '임시추가단어(temporary additional word)'로 취급하여 sub-word token의 평균 임베딩을 임베딩 행렬에 추가해줌
  - 예시 단어 giraffe는 '_gir'와 '_affe'로 여러 개의 sub-word를 지님
- decoder의 input으로 이전 인덱스의 encoder output이 입력되고, 그 결과를 다음 수식을 사용하여 logit 계산함
  > $P(y^{(i)}|x) \propto E \cdot h^{(i)} \in \Reals^N $
- M개의 semantic 카테고리에서 normalized된 확률을 얻기 위해, $V_{seg}$에 없는 단어는 masking 처리한 뒤 softmax 적용
- image backbone의 spatial dimension을 복원하고 bilinear interpolation을 통해 업스케일링 함
- 그렇게 하여 얻은 predictive distribution 중 가장 높은 확률을 가진 카테고리를 반환함
- 주어진 segmentation label $y_{gt}^{(i)}$를 fine-tuning하기 위해, objective로 negative log-likelihood 사용
#### Prompt Design
- text token $x_T$는 task description과 target class와 같은 semantic segmentation task의 디테일을 알려주는 `prompt`로 사용가능
- 또한, VQA(Visual Question Answering) task의 'description + category enumeration' 프로토콜 사용
- 이 디자인에서 VL 모델이 image token $x_I$와 semantic category 사이의 cross-modal relationships를 발견하도록 기대

### Image-free Semantic Segmentation
- 공유된 contextualized embedding space에서 실제 이미지 토큰과 semantic category 단어 토큰이 서로 근접하게 위치하기 때문에, 주어진 단어 토큰을 사용하여 인공적인 이미지 토큰을 생성해 VL 모델을 self-supervised 방법으로 학습시키는 아이디어 제안
- unique category 집합 M으로부터 artificial training data를 구축하고, U*V 크기에 맞게 단어를 랜덤하게 뽑아 grid map 만듬
- grid map의 크기를 image backbone의 spatial resolution에 맞추기 위해 업스케일링 함 → shape regularization effect
  - 이를 통해 실제 이미지와 생성한 가짜 데이터(grid map) 사이의 gap을 줄일 수 있고, object가 랜덤하게 흩어지지 않고 여러 사이즈의 클러스터로 묘사되도록 함
- 최종적으로 artificial image token과 gt를 사용해 모델을 학습시키며, self-supervised training 과정에서 backbone은 freeze함
- image-free 접근인 경우(annotaion 존재X)에 post-processing 적용
  - image feature에 기반하여 output probability를 평균내어 segmentation quality 햐상
  - 특히 cosine 유사도를 사용해 image feature의 K-nearest neighbor를 탐색하고, neighborhood를 사용하여 확률값을 평균냄