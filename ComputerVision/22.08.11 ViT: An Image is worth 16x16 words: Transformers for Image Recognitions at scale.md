# ViT: An Image is worth 16x16 words: Transformers for Image Recognitions at scale(2021)

> - Authors: Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Xhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylbain Gelly, Jakob Uszkoreit, Neil Houlsby
> - Published: ICLR 2021
> - Created: 2022년 08월 11일 오후 1:55
> - Tags: Transformer


## Summary
- NLP 분야에서는 트랜스포머를 사용한 사례 많음. 반면, 당시 기준 CV에서는 한정적임.
- 본 논문에서는 standard transformer를 최소한으로 수정한 모델을 사용하는데, 이때 이미지는 패치로 분리되고, 이 패치들에 대한 linear embedding의 sequence를 트랜스포머의 Input으로 사용함.
- inductive biases도 모델에 넣지 않음
- 큰 데이터셋에 대한 supervised pre-training을 한 경우에 성능이 좋음
- 기존 cnn 기반의 SOTA 결과들과 비교했을 때, 계산량이 훨씬 적고 성능이 우수함