# Pix2Pix: Image-to-Image Translationn with Conditional Adversarial Networks(2017)

> - Authors: Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros
> - Created: 2023년 7월 17일 오후 6:52
> - Published: CVPR 2017
> - Tags: GAN, Image Translation

## Summary
- 본 논문은 Conditional GAN을 사용해 image-to-image translation task를 수행 → pix2pix
- Generator는 U-Net 기반의 아키텍처를 사용했고, Discriminator는 convolutional PatchGAN classifier를 사용함
- Conditional GAN은 output의 연관관계(joint configuration)에 패널티를 부과하는 structured loss를 통해 학습

## Method
- GAN vs cGAN
  - GAN은 random noise vector z로부터 output image y로 맵핑을 학습하는 생성모델
    - $G: z → y$
  - cGAN은 observed image x와 random noise vector z로부터 y의 맵핑을 학습
    - $G: x,z → y$

### 3.1. Objective
- Conditional GAN은 기존 GAN loss에서 condition x를 추가하는데, 본 논문에서 condition x == input image 임.

    $L_{cGAN}(G,D) = \Bbb{E}_y[logD(x,y)] +\Bbb{E}_{x,z}[log(1-D(G(x,z))]$
- traditional loss와 GAN loss를 같이 사용했을 때 더욱 효과적이었다는 이전 연구결과에 기반해 cGAN loss에 L1 loss를 추가해 함께 사용함
  - L1이 L2보다 덜 blurry하기 때문

    $G^* = arg \ \underset{G}{min} \ \underset{D}{max}\ L_{cGAN}(G,D) + \lambda L_{L1}(G)$
- 또한, random noise z를 사용하지 않음
  - z 없이도 Generator를 학습시킬 수 있기 때문
  - Generator의 Dropout layer로 노이즈 생성하고, training 뿐만 아니라 test에도 Dropout layer 사용
### 3.2. Network Architecture
#### Generator with skips
- 이전 연구들은 encoder-decoder 구조의 네트워크를 사용함으로써 high-level feature를 추출함
- 그러나 encoder-decoder는 low-level feature는 손실된다는 문제 존재
- 따라서, UNet 기반의 모델에 skip-connection을 추가함으로써, low-level 정보 손실을 막음
#### PatchGAN
- 이미지를 N*N patch 단위로 쪼개어, 각각의 patch가 real/fake인지 판별 → patch들은 서로 독립이라는 가정을 따름(markov random field)
#### Optimization and Inference
- G를 학습할 때, 기존의 GAN과 달리 $log(1-D(x,G(x,z))$를 최소화하지 않고 최대화하도록 수정
- 또한, D를 최적화할 때 objective를 2로 나누어 G보다 천천히 학습되도록 함
- Inference 과정에서는 Dropout을 그대로 사용해주었고, batch normalization을 할 때 train batch statistic이 아닌 test batch statistic 사용