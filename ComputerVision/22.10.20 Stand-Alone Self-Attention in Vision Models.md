# Stand-Alone Self-Attention in Vision Models(2019)

> - Authors: Prajit Ramachandran, Niki Parmar, Ashish Vaswani, Irwan Bello, Anselm Levskaya, Jonathon Shlens
> - 생성일: 2022년 10월 20일 오후 2:09
> - 태그: Attention

## Summary

- ViT 등장 전, 처음으로 Self-Attention을 CV에 적용한 모델
- CNN은 이미지 분야에서 성능을 높이 향상시켰고, “locality” 특성을 잘 살림
    - 여기서 locality 특성이란 주변 픽셀과의 relation이 높고 거리가 멀어질수록 그 정도가 떨어지는 것을 의미.
    - 그러나 이 특성은 long range dependency를 잘 못살리기 때문에 long-range interaction이 어렵다는 단점을 가짐
- 이 문제를 해결하기 위해 attention이 등장하였으며, 저자는 attention layer를 사용하여 convolutional layer를 대체할 수 있는 stand-alone attention network를 제안함.
- local attention layer
    - key, query, value를 그대로 사용하지 않고 weight layer로 한 번 더 transform 해준 뒤 사용
    - NLP처럼 global attention을 사용할 경우 computational cost가 발생하므로, local attention 사용
    - query 픽셀과 key 픽셀을 내적한 후, 소프트맥스 함수를 취해 similarity matrix 생성하고, 이를 value 픽셀과 내적해 output으로 사용 ⇒ 해당 픽셀과 주변 픽셀 사이의 relational information 학습하도록 유도
        - 논문에서는 single-head가 아닌 multi-head attention을 사용하므로, head당 query, key, value에 각각 다른 트랜스폼 적용해 다양한 representation 학습하도록 함
- positional encoding 추가하여, positional information 학습
    - relative positional embedding 사용
- stem block에 local attention layer를 사용하면 초반 input에서 spatially correlation 정보를 학습하기 어려움
    - 따라서,  convolutional stem으로 교체 후 사용
- ImageNet Classification과 COCO OD에서 높은 성능을 보임