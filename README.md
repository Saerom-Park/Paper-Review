# Paper-Review
논문을 읽고 간단하게 요약하여 올리는 repository!

## Computer-Vision
### CNN
- Xception: Deep Learning with Depthwise Separable Convolutions(2017) [ [arxiv](https://arxiv.org/abs/1610.02357) / [review](https://github.com/Saerom-Park/Paper-Review/blob/master/ComputerVision/Xception.md) ]

### Segmentation
- Unet: Convolutional Networks for Biomedical Image Segmentation(2015) [ [arxiv](https://arxiv.org/abs/1505.04597) / [review]() ]

### Object Detection
- Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks(2016) [ [arxiv](https://arxiv.org/abs/1506.01497) / [review](https://github.com/Saerom-Park/Paper-Review/blob/master/ComputerVision/Faster%20R-CNN.md) ]
- 
### Transformer(Attention)
- ViT: An Image is worth 16x16 words: Transformers for Image Recognitions at scale(2021) [ [arxiv](https://arxiv.org/abs/2010.11929) / [review](https://github.com/Saerom-Park/Paper-Review/blob/master/ComputerVision/ViT%3A%20An%20Image%20is%20worth%2016x16%20words%3A%20Transformers%20for%20Image%20Recognitions%20at%20scale.md) ]
- LightHam: Is Attention Better Than Matrix Decomposition?(2021) [[arxiv](https://openreview.net/forum?id=1FvkSpWosOl) / [github](https://github.com/Gsunshine/Enjoy-Hamburger) / [review]() ]
- Stand-Alone Self-Attention in Vision Models(2019) [ [arxiv](https://arxiv.org/abs/1906.05909) / [review](https://github.com/Saerom-Park/Paper-Review/blob/master/ComputerVision/Stand-Alone%20Self-Attention%20in%20Vision%20Models.md) ]

### GAN
- 

## Language(NLP)
- Bert:Pre-training of Deep Bidirectional Transformers for Language Understanding(2019) [ [arxiv](https://arxiv.org/abs/1810.04805) / [review]()]